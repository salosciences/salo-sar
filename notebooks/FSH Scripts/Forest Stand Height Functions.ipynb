{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest Stand Height Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let Import relevant packages\n",
    "import numpy as np\n",
    "import read_rsc_data as rrd\n",
    "import sys\n",
    "import pdb\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Crop_ISCE:\n",
    "    xmlfile = \"resampleOnlyImage.amp.xml\"\n",
    "    tree = ET.parse(xmlfile)\n",
    "    root = tree.getroot()\n",
    "    size_array = np.array([])\n",
    "    for size in root.iter('property'):\n",
    "        if size.items()[0][1] == 'size':\n",
    "            size_array = np.append(size_array, int(size.find('value').text))\n",
    "    width = size_array[0]\n",
    "    length = size_array[1]\n",
    "    \n",
    "    nanval = 0\n",
    "    \n",
    "    # Read amp files in radar coordinates\n",
    "    amp_file = np.fromfile(\"resampOnlyImage.amp\", dtype = 'complex64')\n",
    "    inty = amp_file.reshape((length, width))\n",
    "    \n",
    "    # Creating empty array for cropped square list\n",
    "    \n",
    "    inty[:176,:] = nanval\n",
    "    inty[5488:,:] = nanval\n",
    "    inty[:,:163] = nanval\n",
    "    inty[:,4846:] = nanval\n",
    "    \n",
    "    # Write output files\n",
    "    inty.tofile(\"resampOnlyImage.amp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Crop_ROIPAC(directory, date1, date2):\n",
    "    # Extract ROI_PAC parameters\n",
    "    amp_rsc_file = date1 + \"-\" + date2 + \"-\" + \"_2rlk.amp.rsc\"\n",
    "    width = int(rrd.read_rsc_data(amp_rsc_file, directory, \"WIDTH\"))\n",
    "    length = int(rrd.read_rsc_data(amp_rsc_file, directory, \"FILE_LENGTH\"))\n",
    "    fullwidth = width*2\n",
    "    nanval = 0\n",
    "    \n",
    "    # Readcpr files in radar coordinates\n",
    "    cor_file = np.fromfile(directory + date1 + \"-\" + date2 + \"_2rlks.cor\", dtype = \"f4\", count = length*fullwidth)\n",
    "    corr = cor_file.reshape((length, fullwidth))\n",
    "    mag = corr[:, 0:width]\n",
    "    phs = corr[:.width:fullwidth]\n",
    "    \n",
    "    # Read amp files in radar coordinates\n",
    "    amp_file = np.fromfile(directory + date1 + \"-\" + date2 + \"_2rlks.amp\", dtype = 'complex64')\n",
    "    inty = amp_file.reshape((length, width))\n",
    "    \n",
    "    # Creating empty array for cropped square list\n",
    "    mag[:638, :] = nanval\n",
    "    mag[3288:, :] = nanval\n",
    "    mag[:,:84] = nanval\n",
    "    mag[:,2418:] = nanval\n",
    "    \n",
    "    phs[:638, :] = nanval\n",
    "    phs[3288:, :] = nanval\n",
    "    phs[:,:84] = nanval\n",
    "    phs[:,2418:] = nanval\n",
    "    \n",
    "    inty[:638, :] = nanval\n",
    "    inty[3288:, :] = nanval\n",
    "    inty[:,:84] = nanval\n",
    "    inty[:,2418:] = nanval\n",
    "    \n",
    "    # Writing values\n",
    "    c_out[:, 0:width] = mag\n",
    "    c_out[:,width:fullwidth] = phs\n",
    "    \n",
    "    # Write output files\n",
    "    cx = c_out.astype('f4')\n",
    "    cx.tofile(directory + date1 + \"-\" + date2 + \"_2rlks_fix.cor\")\n",
    "    inty.tofile(directory + date1 + \"-\" + date2 + \"_2rlks_fix.amp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arc_sin(x, C_param):\n",
    "    # Get rid of extreme values by set all values where x > 1 equal to 1, and x < 0 equal to 0\n",
    "    x[(x > 1)] = 1\n",
    "    x[(x < 0)] = 0\n",
    "    \n",
    "    # Create array of increments between 0 and pi of size pi/100\n",
    "    XX = linspace(0, math.pi, num = 100, endpoint = True)\n",
    "    \n",
    "    # Set the first value of XX to eps to avoid division by zero issues\n",
    "    XX[0] = spacing(1)\n",
    "    \n",
    "    # Calculate sinc for for XX and save it to YY\n",
    "    ## YY - sinc(XX / math.pi)\n",
    "    YY = np.sin(XX) / XX\n",
    "    \n",
    "    # Reset the first value of XX to zero and the first value of YY to the corresponding output\n",
    "    XX[0] = 0\n",
    "    YY[0] = 1\n",
    "    \n",
    "    # Set the last value of YY to 0 to avoid NaN issues\n",
    "    YY[-1] = 0\n",
    "    \n",
    "    # Flip XX and YY left to right\n",
    "    YY = YY[::-1]\n",
    "    XX = XX[::-1]\n",
    "    \n",
    "    # Run interpolation\n",
    "    # XX and YY are your original values, x is the query value, and y is the interpolated values that correspond to x\n",
    "    y = interp_func(x)\n",
    "    \n",
    "    # Set all values in y less than 0 equal to 0\n",
    "    y[(y < 0)] = 0\n",
    "    # return y\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters are the numbers of scenes, edges, start scene, iterations, the input/output file directory, \n",
    "    # averaging numbers in lat and lon for \"self\" and \"pairwise\" fitting, bin_size for density calculation in scatter plot fitting, \n",
    "    # flag for sparse data cloud filtering.\n",
    "def auto_mosaicking_new(scenes, edges, start_scene, N, linkarray, directory, Nd_pairwise, Nd_self, bin_size, flag_sparse):\n",
    "    # Set average S and C parameters (0 < s < 1, 0 < c < 20 so s = 0.65, and c = 13)\n",
    "    avg_S = 0.65\n",
    "    avg_C = 13\n",
    "    \n",
    "    # Create avg_dp matric, and fill with average S and C parameters\n",
    "    avg_dp = zeros(scenes * 2)\n",
    "    put(avg_dp, range(0, scenes * 2, 2), avg_S)\n",
    "    put(avg_dp, range(1, scenes * 2, 2), avg_C)\n",
    "    \n",
    "    # Create the dp matrix\n",
    "    # the difference of the avg and the initial SC values OR all the zeros (avg)\n",
    "    dp = zeros(scenes * 2)\n",
    "    \n",
    "    # Intialize target matrix nd fill with K = 1, B = 0\n",
    "    target_KB = zeros((edges + 1) * 2)\n",
    "    put(target_KB, range(0, (edges + 1) * 2, 2), 1)\n",
    "    \n",
    "    # Run cal_KB()\n",
    "    Y = cKB.cal_KB(dp, edges, start_scene, linkarray, directory, Nd_pairwise, Nd_self, bin_size, flag_sparse)\n",
    "    \n",
    "    # Calculate the residual for cal_KB - target\n",
    "    res = sum((Y - target_KB)**2)\n",
    "    \n",
    "    # Save dp and the residuals as the first iteration output file (using JSON)\n",
    "    iter_file = open(os.path.join(dirextory, \"output\", \"SC_0_iter.json\"), 'w')\n",
    "    json.dump([dp.tolist(), res], iter_file)\n",
    "    iter_file.close()\n",
    "    \n",
    "    # For the rest of the iterations run ls_deltaSC() and save to output file (using JSON)\n",
    "    for i in range(1, N + 1, 2): # This will run from i = 1 to i = N\n",
    "        [dp, res] = lSC.ls_deltaSC(dp, edges, scenes, start_scene, linkarray, directory, Nd_pairwise, Nd_self, bin_size, flag_sparse)\n",
    "        print(\"%d iterations completed!\\n\" % i)\n",
    "        print(time.strftime(\"%H:%M:%S\"))\n",
    "        filename = \"SC_%d_iter.json\" % i\n",
    "        iter_file = open(os.path.join(directory, \"output\", filename), 'w')\n",
    "        json.dump([dp.tolist(), res], iter_file)\n",
    "        iter_file.close()\n",
    "        \n",
    "    print(\"auto_mosaicking_new finsihed at \" + (time.strftime(\"%H:%M:%S\")))\n",
    "    \n",
    "# if function is run on its own, gather parameters from the command line and run the function\n",
    "def main():\n",
    "    # Gather parameters from the command line an drun the function\n",
    "    parser = argparse.ArgumentParser(description = \"Run auto_mosaicking_new script\")\n",
    "    parser.add_argument('scenes', type = int, help = 'number of scenes')\n",
    "    parser.add_argument('edges', type = int, help = 'number of edges')\n",
    "    parser.add_argument('start_scene', type = int, help = 'flag value of the start scene')\n",
    "    parser.add_argument('iterations', type = int, help = 'number of iterations')\n",
    "    parser.add_argument('linkfilename', type = str, help = 'filename of the linkfile')\n",
    "    parser.add_argument('file_directory', type = str, help = 'path of the file directory')\n",
    "    parser.add_argument('--Nd_pairwise', type = int, help = 'pixel-averaging parameter for edge  fitting', nargs = '?', default = 20)\n",
    "    parser.add_argument('--Nd_self', type = int, help = 'pixel-averaging paramenter for central scene fitting', nargs = '?', default = 10)\n",
    "    parser.add_argument('--bin_size', type = int, help = 'bin size for density calculation in sparse data cloud fitting', nargs = '?', default = 100)\n",
    "    parser.add_argument('--flag_sparse', type = int, help = 'optional flag for sparse data clout filtering', choices = [0, 1], nargs = '?', default = 0)\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Create the linkarray from the linkfile name, rather than trying to pass a 2D array in the command line\n",
    "    linkarray = rlf.read_linkfile(args.edges, args.linkfulename, args.file_directory)\n",
    "    \n",
    "    auto_mosaicking_new(args.scenes, args.edges, args.start_scene, args.iterations, linkarray, args.file_directory, args.Nd_pairwise, args.Nd_self, args.bin_size, args_flag_sparse)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
